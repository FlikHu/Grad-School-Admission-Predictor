{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import matplotlib.mlab as mlab\n",
    "from collections import defaultdict\n",
    "from sklearn import svm \n",
    "from sklearn import linear_model\n",
    "from sklearn import dummy\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('all_clean.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate GRE scores to percentile so we can compare old/new GRE\n",
    "# (verbal, quantiative)\n",
    "newGREPercentileDict = {\n",
    "    170: (99,96),\n",
    "    169: (99,96),\n",
    "    168: (98,94),\n",
    "    167: (98,91),\n",
    "    166: (97,90),\n",
    "    165: (96,88),\n",
    "    164: (94,86),\n",
    "    163: (93,83),\n",
    "    162: (91,80),\n",
    "    161: (88,77),\n",
    "    160: (86,74),\n",
    "    159: (83,72),\n",
    "    158: (80,68),\n",
    "    157: (76,65),\n",
    "    156: (73,61),\n",
    "    155: (69,58),\n",
    "    154: (65,54),\n",
    "    153: (61,50),\n",
    "    152: (56,46),\n",
    "    151: (52,42),\n",
    "    150: (47,38),\n",
    "    149: (42,34),\n",
    "    148: (38,30),\n",
    "    147: (34,26),\n",
    "    146: (31,23),\n",
    "    145: (27,20),\n",
    "    144: (23,16),\n",
    "    143: (20,14),\n",
    "    142: (17,12),\n",
    "    141: (14,10),\n",
    "    140: (11,8),\n",
    "    139: (9,6),\n",
    "    138: (8,4),\n",
    "    137: (6,3),\n",
    "    136: (4,2),\n",
    "    135: (3,2),\n",
    "    134: (2,1),\n",
    "    133: (2,1),\n",
    "    132: (1,1),\n",
    "    131: (1,1),\n",
    "    130:(1,1),\n",
    "}\n",
    "\n",
    "# (verbal, quantitative)\n",
    "oldGREPercentileDict = {\n",
    "    800: (99,91),\n",
    "    790: (99,87),\n",
    "    780: (99,84),\n",
    "    770: (99,78),\n",
    "    760: (99,76),\n",
    "    750: (99,73),\n",
    "    740: (99,69),\n",
    "    730: (98,66),\n",
    "    720: (98,62),\n",
    "    710: (98,59),\n",
    "    700: (97,59),\n",
    "    690: (96,55),\n",
    "    680: (96,51),\n",
    "    670: (94,47),\n",
    "    660: (94,47),\n",
    "    650: (93,43),\n",
    "    640: (91,43),\n",
    "    630: (91,38),\n",
    "    620: (88,35),\n",
    "    610: (86,35),\n",
    "    600: (86,30),\n",
    "    590: (83,30),\n",
    "    580: (80,27),\n",
    "    570: (80,27),\n",
    "    560: (76,24),\n",
    "    550: (73,24),\n",
    "    540: (73,20),\n",
    "    530: (69,20),\n",
    "    520: (65,17),\n",
    "    510: (65,17),\n",
    "    500: (61,17),\n",
    "    490: (56,14),\n",
    "    480: (56,14),\n",
    "    470: (52,12),\n",
    "    460: (52,12),\n",
    "    450: (48,10),\n",
    "    440: (43,10),\n",
    "    430: (43,10),\n",
    "    420: (39,8),\n",
    "    410: (35,8),\n",
    "    400: (31,8),\n",
    "    390: (31,6),\n",
    "    380: (27,6),\n",
    "    370: (24,4),\n",
    "    360: (20,4),\n",
    "    350: (20,4),\n",
    "    340: (17,3),\n",
    "    330: (15,3),\n",
    "    320: (12,2),\n",
    "    310: (9,2),\n",
    "    300: (8,2),\n",
    "    290: (6,2),\n",
    "    280: (3,2),\n",
    "    270: (2,1),\n",
    "    260: (2,1),\n",
    "    250: (1,1),\n",
    "    240: (1,1),\n",
    "    230: (1,1),\n",
    "    220: (1,1),\n",
    "    210: (1,1),\n",
    "    200: (1,1),\n",
    "}\n",
    "\n",
    "# Group different majors(typos/abbreviation/subfields) to improve accuracy\n",
    "majorAggregatorDict = {\n",
    "    'Computer Science': ['computer sc', 'computer and information', \n",
    "                         'machine learning', 'data science', 'eecs', \n",
    "                         'software', 'human computer', 'human-computer'],\n",
    "    'Electrical and Computer Engineering': ['ece','electrical','computer eng','robotic'],\n",
    "    'Economics': ['econ'],\n",
    "    'Mathematics': ['math','computation'],\n",
    "    'English': ['english'],\n",
    "    'Physics': ['physics'],\n",
    "    'Speech Language Pathology': ['speech', 'commu', 'disorder'],\n",
    "    'Political Science': ['politic', 'government', 'international', 'global', 'intl',\n",
    "                          'public admin', 'policy', 'public affairs', 'public rela'],\n",
    "    'Mechanical Engineering': ['mechan'],\n",
    "    'Education': ['education', 'instruct','Curri','teach'],\n",
    "    'Civil Engineering': ['civil'],\n",
    "    'Psychology': ['psychology', 'psych'],\n",
    "    'Anthropology': ['anthrop'],\n",
    "    'Management Science': ['manage'],\n",
    "    'Chemistry': ['chemistry','chems'],\n",
    "    'Chemical Engineering': ['chemical'],\n",
    "    'Statistics': ['stats', 'statis'],\n",
    "    'Biological Science': ['biology', 'biological', 'bio','mole','immu','toxi','gene'],\n",
    "    'Environemntal Science': ['environment'],\n",
    "    'Social/Cultural Studies': ['culture', 'asia', 'africa', 'latin', 'american', 'eastern',\n",
    "                         'east', 'islamic', 'christian', 'arab','gender','women','ethnic'],\n",
    "    'History': ['history', 'historical'],\n",
    "    'Linguistics': ['linguistics', 'language', 'spanish', 'chinese', 'japanese', \n",
    "                    'french', 'italian','german','russian'],\n",
    "    'Neuroscience': ['neuro'],\n",
    "    'Architecture': ['archi'],\n",
    "    'Earth Science': ['earth', 'geo','soil','planet'],\n",
    "    'Finance': ['finan'],\n",
    "    'Material Science': ['material'],\n",
    "    'Social Work': ['social'],\n",
    "    'Industrial Engineering': ['indust'],\n",
    "    'Health Science': ['health','mph'],\n",
    "    'Urban Planning': ['city', 'urban','region','planning'],\n",
    "    'Creative Writing': ['writing'],\n",
    "    'Congnitive Science': ['cogni'],\n",
    "    'Information science': ['information', 'informatic'],\n",
    "    'Criminal Justice': ['crimi'],\n",
    "    'Religious Study': ['religi','divin'],\n",
    "    'Music': ['music'],\n",
    "    'Arts': ['art','media','visual','film','cinema','movie', 'theatre','perform'],\n",
    "    'Literature': ['lite', 'classic'],\n",
    "    'Aerospace Engineering': ['aero'],\n",
    "    'Philosophy': ['philo'],\n",
    "    'Petroleum Engineering': ['petro'],\n",
    "    'Business': ['busi', 'mba'],\n",
    "    'Pharmaceutical Sciences': ['pharma', 'medi'],\n",
    "    'Nuclear Engineering': ['nuclear'],\n",
    "    'Marketing': ['market', 'adv'],\n",
    "    'Operational Research': ['operation'],\n",
    "    'Nano Engineering': ['nano'],\n",
    "    'Energy Science': ['energy'],\n",
    "    'System Engineering': ['system'],\n",
    "    'Therapy and Counseling': ['therapy','couns']\n",
    "}\n",
    "\n",
    "def majorAggregator(major):\n",
    "    for k in majorAggregatorDict.keys():\n",
    "        for majorWord in majorAggregatorDict[k]:\n",
    "            if majorWord in major.lower():\n",
    "                return k\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only care about accepted and rejected entries\n",
    "data = [d for d in data if d[9] != '' and d[10] != '' and d[11] != '' and d[12] != '']\n",
    "data = [d for d in data if d[5] == 'Accepted' or d[5] == 'Rejected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those dict only contains data in the training set\n",
    "majorDict = defaultdict(int)\n",
    "degreeDict = defaultdict(int)\n",
    "universityDict = defaultdict(int)\n",
    "universityAcceptanceRateDict = defaultdict(list)\n",
    "universityGPADict = defaultdict(list)\n",
    "universityGREVDict = defaultdict(list)\n",
    "universityGREQDict = defaultdict(list)\n",
    "universityGREWDict = defaultdict(list)\n",
    "majorAcceptanceRateDict = defaultdict(list)\n",
    "majorGPADict = defaultdict(list)\n",
    "majorGREWDict = defaultdict(list)\n",
    "majorGREVDict = defaultdict(list)\n",
    "majorGREQDict = defaultdict(list)\n",
    "decisionDict = defaultdict(int)\n",
    "statusDict = defaultdict(int)\n",
    "gpas = []\n",
    "greVerbal = []\n",
    "greQuant = []\n",
    "greWriting = []\n",
    "\n",
    "random.shuffle(data)\n",
    "for d in data[:15000]:\n",
    "    uniName = d[1]\n",
    "    major = majorAggregator(d[2])\n",
    "    degree = d[3]\n",
    "    decision = d[5]\n",
    "    gpa = d[9]\n",
    "    greV = d[10]\n",
    "    greQ = d[11]\n",
    "    greW = d[12]\n",
    "    isNewGRE = d[13]\n",
    "    status = d[15]\n",
    "    comment = d[18]\n",
    "    \n",
    "    universityDict[uniName] += 1\n",
    "    majorDict[major] += 1\n",
    "    degreeDict[degree] += 1\n",
    "    decisionDict[decision] += 1\n",
    "    \n",
    "    if decision == 'Accepted':\n",
    "        universityAcceptanceRateDict[uniName].append(1)\n",
    "        majorAcceptanceRateDict[major].append(1)\n",
    "    else:\n",
    "        universityAcceptanceRateDict[uniName].append(0)\n",
    "        majorAcceptanceRateDict[major].append(0)\n",
    "    \n",
    "    if float(gpa) <= 4:\n",
    "        gpas.append(float(gpa))\n",
    "        universityGPADict[uniName].append(float(gpa))\n",
    "        if d[5] == 'Accepted':\n",
    "            majorGPADict[major].append(float(gpa))\n",
    "        \n",
    "    if isNewGRE == 'True':\n",
    "        greVerbal.append(newGREPercentileDict[float(greV)][0])\n",
    "        if d[5] == 'Accepted':\n",
    "            universityGREVDict[uniName].append(newGREPercentileDict[float(greV)][0])\n",
    "            majorGREVDict[major].append(newGREPercentileDict[float(greV)][0])\n",
    "    else:\n",
    "        greVerbal.append(oldGREPercentileDict[float(greV)][0])\n",
    "        if d[5] == 'Accepted':\n",
    "            universityGREVDict[uniName].append(oldGREPercentileDict[float(greV)][0])\n",
    "            majorGREVDict[major].append(oldGREPercentileDict[float(greV)][0])\n",
    "        \n",
    "    if isNewGRE == 'True':\n",
    "        greQuant.append(newGREPercentileDict[float(greQ)][1])\n",
    "        if d[5] == 'Accepted':\n",
    "            universityGREVDict[uniName].append(newGREPercentileDict[float(greQ)][1])\n",
    "            majorGREVDict[major].append(newGREPercentileDict[float(greQ)][1])\n",
    "    else:\n",
    "        greQuant.append(oldGREPercentileDict[float(greQ)][1])\n",
    "        if d[5] == 'Accepted':\n",
    "            universityGREVDict[uniName].append(oldGREPercentileDict[float(greQ)][1])\n",
    "            majorGREVDict[major].append(oldGREPercentileDict[float(greQ)][1])\n",
    "        \n",
    "    if greW != '':\n",
    "        greWriting.append(float(greW))\n",
    "        if d[5] == 'Accepted':\n",
    "            universityGREWDict[uniName].append(float(greW))\n",
    "            majorGREWDict[major].append(float(greW))\n",
    "    else:\n",
    "        greWriting.append(0)\n",
    "    statusDict[status] += 1\n",
    "    \n",
    "# comment analysis\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "wordDict = defaultdict(int)\n",
    "ngramDict = defaultdict(int)\n",
    "goodngramDict = defaultdict(int)\n",
    "goodWordDict = defaultdict(int)\n",
    "# construct feature based on positive comment\n",
    "# so no need to purify words related to rejection\n",
    "\n",
    "# We don't want to predict acceptance if the answer is already presented in the comment section\n",
    "forbiddenWords = ['accepted', 'admitted', 'admission', 'offer', 'fund', 'stipend',\n",
    "                 'TAship', 'official', 'unofficial', 'decline', 'financial', 'assistantship',\n",
    "                 'tuition', 'email', 'phone', 'website', 'excited', 'happy', 'aid','wait','thrill'\n",
    "                 ,'formal', 'spring','fall','notify', 'week', 'receive', 'inform', 'waitlist']\n",
    "forbiddenWords = [stemmer.stem(w) for w in forbiddenWords]\n",
    "forbiddenWords = set(forbiddenWords)\n",
    "\n",
    "# transfer to lower case then stem\n",
    "for d in data[:15000]:  \n",
    "    words = d[18].lower()\n",
    "    words = ''.join([c for c in words if c not in string.punctuation]).split()\n",
    "    for word in words:\n",
    "        word = stemmer.stem(word)\n",
    "        if word not in sw and word not in forbiddenWords and not word.isdigit():\n",
    "            if d[5] == 'Accepted':\n",
    "                goodWordDict[word] += 1\n",
    "            wordDict[word] += 1  \n",
    "        \n",
    "# word frequency\n",
    "freq = defaultdict(float)\n",
    "total = sum(wordDict.values())\n",
    "for word in wordDict.keys():\n",
    "    freq[word] = wordDict[word]/total\n",
    "    \n",
    "goodFreq = defaultdict(float)\n",
    "total1 = sum(goodWordDict.values())\n",
    "for word in goodWordDict.keys():\n",
    "    goodFreq[word] = goodWordDict[word]/total1\n",
    "    \n",
    "tops = [(goodFreq[w] - freq[w], w) for w in goodFreq]\n",
    "tops = sorted(tops, reverse=True)[:200]\n",
    "tops = [word for (freq,word) in tops]\n",
    "\n",
    "accRates = []\n",
    "for uni in universityAcceptanceRateDict.keys():\n",
    "    arr = universityAcceptanceRateDict[uni]\n",
    "    if len(arr) > 10:\n",
    "        accRates.append(sum(arr)/len(arr))\n",
    "\n",
    "print(np.median(accRates),len(accRates))\n",
    "\n",
    "accRatesMajor = []\n",
    "for major in majorAcceptanceRateDict.keys():\n",
    "    arr = majorAcceptanceRateDict[major]\n",
    "    if len(arr) > 10:\n",
    "        accRatesMajor.append(sum(arr)/len(arr))\n",
    "        \n",
    "print(np.median(accRatesMajor),len(accRatesMajor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat(d):\n",
    "    uniName = d[1]\n",
    "    major = majorAggregator(d[2])\n",
    "    degree = d[3]\n",
    "    gpa = d[9]\n",
    "    greV = d[10]\n",
    "    greQ = d[11]\n",
    "    greW = d[12]\n",
    "    isNewGRE = d[13]\n",
    "    greSubject = d[14]\n",
    "    status = d[15]\n",
    "    comment = d[18]\n",
    "    \n",
    "    feature = []\n",
    "    # acceptance rate of target university\n",
    "    admissionResUni = universityAcceptanceRateDict[uniName]\n",
    "    if len(admissionResUni) > 10:\n",
    "        feature.append(sum(admissionResUni)/len(admissionResUni))\n",
    "    else:\n",
    "        feature.append(0.68)\n",
    "        \n",
    "    # acceptance rate of intended major\n",
    "    admissionResMajor = majorAcceptanceRateDict[major]\n",
    "    if len(admissionResMajor) > 10:\n",
    "        feature.append(sum(admissionResMajor)/len(admissionResMajor))\n",
    "    else:\n",
    "        feature.append(0.58)\n",
    "    \n",
    "    # difference between the GPA and the median GPA of the target university\n",
    "    medianGPAUni = 3.6\n",
    "    if len(universityGPADict[uniName]) > 10:\n",
    "        medianGPAUni = np.median(universityGPADict[uniName])\n",
    "    feature.append(float(gpa) - medianGPAUni)\n",
    "    \n",
    "    greVMedian = 80;\n",
    "    if len(majorGREVDict[major]) > 10:\n",
    "        greVMedian = np.median(majorGREVDict[major])\n",
    "        \n",
    "    greQMedian = 77;\n",
    "    if len(majorGREQDict[major]) > 10:\n",
    "        greQMedian = np.median(majorGREQDict[major])\n",
    "    \n",
    "    # GRE percentile\n",
    "    if isNewGRE == 'True':\n",
    "            feature.append(newGREPercentileDict[float(greV)][0] - greVMedian)\n",
    "            feature.append(newGREPercentileDict[float(greQ)][1] - greQMedian)\n",
    "    else:\n",
    "            feature.append(oldGREPercentileDict[float(greV)][0] - greVMedian)\n",
    "            feature.append(oldGREPercentileDict[float(greQ)][1] - greQMedian)\n",
    "    \n",
    "    #difference between GRE writing score and the GRE writing score of intended major\n",
    "    greWMedianMajor = 4\n",
    "    if len(majorGREWDict[major]) > 10:\n",
    "        greWMedianMajor = np.median(majorGREWDict[major])\n",
    "        \n",
    "    if greW != '':\n",
    "        feature.append(float(greW) - greWMedianMajor)\n",
    "    else:\n",
    "        feature.append(0)\n",
    "        \n",
    "    # degree type\n",
    "    if degree == 'PhD':\n",
    "        feature += [1,0]\n",
    "    else:\n",
    "        feature += [0,1]\n",
    "        \n",
    "    # residency status\n",
    "    if status == 'American':\n",
    "        feature += [1,0,0]\n",
    "    elif status == 'International with US Degree':\n",
    "        feature += [0,1,0]\n",
    "    else:\n",
    "        feature += [0,0,1]\n",
    "    \n",
    "    # comments (unigram)\n",
    "    comment = comment.lower()\n",
    "    comment = ''.join([c for c in comment if c not in string.punctuation]).split()\n",
    "    wordSet = set()\n",
    "    for word in comment:\n",
    "        word = stemmer.stem(word)\n",
    "        wordSet.add(word)\n",
    "       \n",
    "    feature += [w in wordSet for w in tops]\n",
    "    return feature\n",
    "\n",
    "X = [feat(d) for d in data]\n",
    "y = [d[5] == 'Accepted' for d in data]\n",
    "\n",
    "training_X = X[:15000]\n",
    "training_y = y[:15000]\n",
    "\n",
    "validation_X = X[15000:30000]\n",
    "validation_y = y[15000:30000]\n",
    "\n",
    "testing_X = X[30000:45000]\n",
    "testing_y = y[30000:45000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "# pred = []\n",
    "# for d in data[15000:30000]:\n",
    "#     uniName = d[1]\n",
    "#     major = majorAggregator(d[2])\n",
    "#     degree = d[3]\n",
    "#     gpa = float(d[9])\n",
    "    \n",
    "#     if gpa > np.median(universityGPADict[uniName]) and gpa > np.median(majorGPADict[major]):\n",
    "#         pred.append(True)\n",
    "#     else:\n",
    "#         pred.append(False)\n",
    "    \n",
    "# validation(pred,validation_y)\n",
    "\n",
    "# dummyClf = dummy.DummyClassifier(strategy='stratified')\n",
    "# dummyClf.fit(training_X,training_y)\n",
    "# pred = dummyClf.predict(validation_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = [0.01,0.1,1]\n",
    "# preds = []\n",
    "# predTitles = []\n",
    "\n",
    "\n",
    "# for param in params:\n",
    "#     clf = svm.LinearSVC(C=param, loss='hinge', intercept_scaling=20, class_weight='balanced')\n",
    "#     clf.fit(training_X,training_y)\n",
    "#     pred = clf.predict(validation_X)\n",
    "\n",
    "#     clf1 = linear_model.LogisticRegression(C=param, penalty='l1',class_weight='balanced')\n",
    "#     clf1.fit(training_X,training_y)\n",
    "#     pred1 = clf1.predict(validation_X)\n",
    "\n",
    "#     predTitles += ['SVM C='+str(param), 'Logistic C='+str(param)]\n",
    "#     preds += [pred, pred1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(pred,v_y):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for (x,y) in zip(pred,v_y):\n",
    "        if(x == y):\n",
    "            if y:\n",
    "                TP +=1\n",
    "            else: \n",
    "                TN += 1\n",
    "        elif x:\n",
    "            FP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "\n",
    "    print('TPR: ', (TP/(TP+FN)))\n",
    "    print('TNR: ', (TN/(TN+FP)))\n",
    "    print('Accuracy: ', sum([x == y for (x,y) in zip(pred,v_y)])/len(v_y))\n",
    "    FPR, TPR, _ = metrics.roc_curve(v_y, pred, pos_label=True)\n",
    "    print('AUC: ', metrics.auc(FPR, TPR),'\\n')\n",
    "\n",
    "# for (pred,predTitle) in zip(preds,predTitles):\n",
    "#     validation(pred,validation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdf = RandomForestClassifier(n_estimators=2000, min_samples_leaf=2, class_weight='balanced', n_jobs=-1)\n",
    "# rdf.fit(training_X,training_y)\n",
    "# pred1 = rdf.predict(testing_X)\n",
    "# validation(pred1,testing_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = rdf.feature_importances_\n",
    "# print(f[:12],sum(f[12:]))\n",
    "\n",
    "# importance = {\n",
    "#     'Experience': sum(f[12:]),\n",
    "#     'Acceptance Rate of Target University': f[0],\n",
    "#     'Acceptance Rate of Intended Major': f[1],\n",
    "#     'GPA': f[2],\n",
    "#     'GRE Verbal Percentile': f[3],\n",
    "#     'GRE Quantitative Percentile': f[4],\n",
    "#     'GRE Writing': f[5],\n",
    "#     'Intended Degree': np.mean(f[6]+f[7]),\n",
    "#     'Residency Status': np.mean(f[8:11]),\n",
    "# }\n",
    "\n",
    "# name = []\n",
    "# score = []\n",
    "# for k in sorted(importance, key=importance.get, reverse=True):\n",
    "#     name.append(k)\n",
    "#     score.append(importance[k])\n",
    "    \n",
    "    \n",
    "# y_pos = np.arange(len(name))\n",
    "# plt.barh(y_pos, score, align='center', alpha=0.5)\n",
    "# plt.yticks(y_pos, name)\n",
    "# plt.xlabel('Importance')\n",
    "# plt.title('Features Importance')\n",
    "\n",
    "# f, t, _ = metrics.roc_curve(testing_y, pred1)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(f, t)\n",
    "# plt.plot([0,0.5,1],[0,0.5,1])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Testing code ommited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "############################################################################################################################################\n",
    "# Using the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the helper dicts but with all data in the dataset\n",
    "universityAcceptanceRateDict = defaultdict(list)\n",
    "universityGPADict = defaultdict(list)\n",
    "universityGREVDict = defaultdict(list)\n",
    "universityGREQDict = defaultdict(list)\n",
    "universityGREWDict = defaultdict(list)\n",
    "majorAcceptanceRateDict = defaultdict(list)\n",
    "majorGPADict = defaultdict(list)\n",
    "majorGREWDict = defaultdict(list)\n",
    "majorGREVDict = defaultdict(list)\n",
    "majorGREQDict = defaultdict(list)\n",
    "\n",
    "random.shuffle(data)\n",
    "for d in data:\n",
    "    uniName = d[1]\n",
    "    major = majorAggregator(d[2])\n",
    "    degree = d[3]\n",
    "    decision = d[5]\n",
    "    gpa = d[9]\n",
    "    greV = d[10]\n",
    "    greQ = d[11]\n",
    "    greW = d[12]\n",
    "    isNewGRE = d[13]\n",
    "    status = d[15]\n",
    "    comment = d[18]\n",
    "    \n",
    "    if decision == 'Accepted':\n",
    "        universityAcceptanceRateDict[uniName].append(1)\n",
    "        majorAcceptanceRateDict[major].append(1)\n",
    "    else:\n",
    "        universityAcceptanceRateDict[uniName].append(0)\n",
    "        majorAcceptanceRateDict[major].append(0)\n",
    "    \n",
    "    if float(gpa) <= 4:\n",
    "        if d[5] == 'Accepted':\n",
    "            majorGPADict[major].append(float(gpa))\n",
    "        \n",
    "    if isNewGRE == 'True':\n",
    "        if d[5] == 'Accepted':\n",
    "            universityGREVDict[uniName].append(newGREPercentileDict[float(greV)][0])\n",
    "            majorGREVDict[major].append(newGREPercentileDict[float(greV)][0])\n",
    "    else:\n",
    "        if d[5] == 'Accepted':\n",
    "            universityGREVDict[uniName].append(oldGREPercentileDict[float(greV)][0])\n",
    "            majorGREVDict[major].append(oldGREPercentileDict[float(greV)][0])\n",
    "        \n",
    "    if isNewGRE == 'True':\n",
    "        if d[5] == 'Accepted':\n",
    "            universityGREVDict[uniName].append(newGREPercentileDict[float(greQ)][1])\n",
    "            majorGREVDict[major].append(newGREPercentileDict[float(greQ)][1])\n",
    "    else:\n",
    "        if d[5] == 'Accepted':\n",
    "            universityGREVDict[uniName].append(oldGREPercentileDict[float(greQ)][1])\n",
    "            majorGREVDict[major].append(oldGREPercentileDict[float(greQ)][1])\n",
    "        \n",
    "    if greW != '':\n",
    "        if d[5] == 'Accepted':\n",
    "            universityGREWDict[uniName].append(float(greW))\n",
    "            majorGREWDict[major].append(float(greW))\n",
    "    \n",
    "# comment analysis\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "wordDict = defaultdict(int)\n",
    "ngramDict = defaultdict(int)\n",
    "goodngramDict = defaultdict(int)\n",
    "goodWordDict = defaultdict(int)\n",
    "# construct feature based on positive comment\n",
    "# so no need to purify words related to rejection\n",
    "forbiddenWords = ['accepted', 'admitted', 'admission', 'offer', 'fund', 'stipend',\n",
    "                 'TAship', 'official', 'unofficial', 'decline', 'financial', 'assistantship',\n",
    "                 'tuition', 'email', 'phone', 'website', 'excited', 'happy', 'aid']\n",
    "forbiddenWords = [stemmer.stem(w) for w in forbiddenWords]\n",
    "forbiddenWords = set(forbiddenWords)\n",
    "\n",
    "for d in data:  \n",
    "    words = d[18].lower()\n",
    "    words = ''.join([c for c in words if c not in string.punctuation]).split()\n",
    "            \n",
    "    for word in words:\n",
    "        word = stemmer.stem(word)\n",
    "        if word not in sw and word not in forbiddenWords:\n",
    "            if d[5] == 'Accepted':\n",
    "                goodWordDict[word] += 1\n",
    "            wordDict[word] += 1  \n",
    "        \n",
    "# word frequency\n",
    "freq = defaultdict(float)\n",
    "total = sum(wordDict.values())\n",
    "for word in wordDict.keys():\n",
    "    freq[word] = wordDict[word]/total\n",
    "    \n",
    "goodFreq = defaultdict(float)\n",
    "total1 = sum(goodWordDict.values())\n",
    "for word in goodWordDict.keys():\n",
    "    goodFreq[word] = goodWordDict[word]/total1\n",
    "    \n",
    "tops = [(goodFreq[w] - freq[w], w) for w in goodFreq]\n",
    "tops = sorted(tops, reverse=True)[:500]\n",
    "tops = [word for (freq,word) in tops]\n",
    "\n",
    "def feat(d):\n",
    "    uniName = d[1]\n",
    "    major = majorAggregator(d[2])\n",
    "    degree = d[3]\n",
    "    gpa = d[9]\n",
    "    greV = d[10]\n",
    "    greQ = d[11]\n",
    "    greW = d[12]\n",
    "    isNewGRE = d[13]\n",
    "    greSubject = d[14]\n",
    "    status = d[15]\n",
    "    comment = d[18]\n",
    "    \n",
    "    feature = []\n",
    "    # acceptance rate of target university\n",
    "    admissionResUni = universityAcceptanceRateDict[uniName]\n",
    "    if len(admissionResUni) > 10:\n",
    "        feature.append(sum(admissionResUni)/len(admissionResUni))\n",
    "    else:\n",
    "        feature.append(0.68)\n",
    "        \n",
    "    # acceptance rate of intended major\n",
    "    admissionResMajor = majorAcceptanceRateDict[major]\n",
    "    if len(admissionResMajor) > 10:\n",
    "        feature.append(sum(admissionResMajor)/len(admissionResMajor))\n",
    "    else:\n",
    "        feature.append(0.58)\n",
    "    \n",
    "    # difference between the GPA and the median GPA of the target university\n",
    "    medianGPAUni = 3.6\n",
    "    if len(universityGPADict[uniName]) > 10:\n",
    "        medianGPAUni = np.median(universityGPADict[uniName])\n",
    "    feature.append(float(gpa) - medianGPAUni)\n",
    "    \n",
    "    # difference between the GPA and the median GPA of the intended major\n",
    "    medianGPAMajor = 3.6\n",
    "    if len(majorGPADict[major]) > 10:\n",
    "        medianGPAMajor = np.median(majorGPADict[major])\n",
    "    feature.append(float(gpa) - medianGPAMajor)\n",
    "\n",
    "    # degree type\n",
    "    if degree == 'PhD':\n",
    "        feature += [1,0]\n",
    "    else:\n",
    "        feature += [0,1]\n",
    "    \n",
    "    greVMedian = 80;\n",
    "    if len(majorGREVDict[major]) > 10:\n",
    "        greVMedian = np.median(majorGREVDict[major])\n",
    "        \n",
    "    greQMedian = 77;\n",
    "    if len(majorGREQDict[major]) > 10:\n",
    "        greQMedian = np.median(majorGREQDict[major])\n",
    "    \n",
    "    # GRE percentile\n",
    "    if isNewGRE == 'True':\n",
    "            feature.append(newGREPercentileDict[float(greV)][0] - greVMedian)\n",
    "            feature.append(newGREPercentileDict[float(greQ)][1] - greQMedian)\n",
    "    else:\n",
    "            feature.append(oldGREPercentileDict[float(greV)][0] - greVMedian)\n",
    "            feature.append(oldGREPercentileDict[float(greQ)][1] - greQMedian)\n",
    "    \n",
    "    # difference between GRE writing score and the GRE writing score of target university\n",
    "    greWMedianUni = 4\n",
    "    if len(universityGREWDict[uniName]) > 10:\n",
    "        greWMedianUni = np.median(universityGREWDict[uniName])\n",
    "        \n",
    "    if greW != '':\n",
    "        feature.append(float(greW) - greWMedianUni)\n",
    "    else:\n",
    "        feature.append(0)\n",
    "    \n",
    "#     difference between GRE writing score and the GRE writing score of intended major\n",
    "    greWMedianMajor = 4\n",
    "    if len(majorGREWDict[major]) > 10:\n",
    "        greWMedianMajor = np.median(majorGREWDict[major])\n",
    "        \n",
    "    if greW != '':\n",
    "        feature.append(float(greW) - greWMedianMajor)\n",
    "    else:\n",
    "        feature.append(0)\n",
    "    \n",
    "    # residency status\n",
    "    if status == 'American':\n",
    "        feature += [1,0,0,0]\n",
    "    elif status == 'International with US Degree':\n",
    "        feature += [0,1,0,0]\n",
    "    elif status == 'International':\n",
    "        feature += [0,0,1,0]\n",
    "    else:\n",
    "        feature += [0,0,0,1]\n",
    "    \n",
    "    comment = comment.lower()\n",
    "    comment = ''.join([c for c in comment if c not in string.punctuation]).split()\n",
    "    wordSet = set()\n",
    "    \n",
    "    # comment analysis (unigram)\n",
    "    for word in comment:\n",
    "        word = stemmer.stem(word)\n",
    "        wordSet.add(word)\n",
    "       \n",
    "    feature += [w in wordSet for w in tops]\n",
    "    return feature\n",
    "\n",
    "X = [feat(d) for d in data]\n",
    "y = [d[5] == 'Accepted' for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "rdf = RandomForestClassifier(n_estimators=1000, min_samples_leaf=2, class_weight='balanced', n_jobs=-1)\n",
    "rdf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model so you only need to train it once\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rdf, open('predictor', 'wb'))\n",
    "pickle.dump(newGREPercentileDict, open('newGREPercentileDict', 'wb'))\n",
    "pickle.dump(oldGREPercentileDict, open('oldGREPercentileDict', 'wb'))\n",
    "pickle.dump(majorAggregatorDict, open('majorAggregatorDict', 'wb'))\n",
    "\n",
    "pickle.dump(universityAcceptanceRateDict, open('universityAcceptanceRateDict', 'wb'))\n",
    "pickle.dump(universityGPADict, open('universityGPADict', 'wb'))\n",
    "pickle.dump(universityGREVDict, open('universityGREVDict', 'wb'))\n",
    "pickle.dump(universityGREQDict, open('universityGREQDict', 'wb'))\n",
    "pickle.dump(universityGREWDict, open('universityGREWDict', 'wb'))\n",
    "pickle.dump(majorAcceptanceRateDict, open('majorAcceptanceRateDict', 'wb'))\n",
    "pickle.dump(majorGPADict, open('majorGPADict', 'wb'))\n",
    "pickle.dump(majorGREVDict, open('majorGREVDict', 'wb'))\n",
    "pickle.dump(majorGREQDict, open('majorGREQDict', 'wb'))\n",
    "pickle.dump(majorGREWDict, open('majorGREWDict', 'wb'))\n",
    "pickle.dump(tops, open('tops', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "rdf = pickle.load(open('predictor', 'rb'))\n",
    "newGREPercentileDict = pickle.load(open('newGREPercentileDict', 'rb'))\n",
    "oldGREPercentileDict = pickle.load(open('oldGREPercentileDict', 'rb'))\n",
    "majorAggregatorDict = pickle.load(open('majorAggregatorDict', 'rb'))\n",
    "\n",
    "universityAcceptanceRateDict = pickle.load(open('universityAcceptanceRateDict', 'rb'))\n",
    "universityGPADict = pickle.load(open('universityGPADict', 'rb'))\n",
    "universityGREVDict = pickle.load(open('universityGREVDict', 'rb'))\n",
    "universityGREQDict = pickle.load(open('universityGREQDict', 'rb'))\n",
    "universityGREWDict = pickle.load(open('universityGREWDict', 'rb'))\n",
    "majorAcceptanceRateDict = pickle.load(open('majorAcceptanceRateDict', 'rb'))\n",
    "majorGPADict = pickle.load(open('majorGPADict', 'rb'))\n",
    "majorGREVDict = pickle.load(open('majorGREVDict', 'rb'))\n",
    "majorGREQDict = pickle.load(open('majorGREQDict', 'rb'))\n",
    "majorGREWDict = pickle.load(open('majorGREWDict', 'rb'))\n",
    "tops = pickle.load(open('tops', 'rb'))\n",
    "\n",
    "\n",
    "def majorAggregator(major):\n",
    "    for k in majorAggregatorDict.keys():\n",
    "        for majorWord in majorAggregatorDict[k]:\n",
    "            if majorWord in major.lower():\n",
    "                return k\n",
    "    return 'other'\n",
    "\n",
    "\n",
    "def feat(d):\n",
    "    uniName = d[1]\n",
    "    major = majorAggregator(d[2])\n",
    "    degree = d[3]\n",
    "    gpa = d[9]\n",
    "    greV = d[10]\n",
    "    greQ = d[11]\n",
    "    greW = d[12]\n",
    "    isNewGRE = d[13]\n",
    "    greSubject = d[14]\n",
    "    status = d[15]\n",
    "    comment = d[18]\n",
    "    \n",
    "    feature = []\n",
    "    # acceptance rate of target university\n",
    "    admissionResUni = universityAcceptanceRateDict[uniName]\n",
    "    if len(admissionResUni) > 10:\n",
    "        feature.append(sum(admissionResUni)/len(admissionResUni))\n",
    "    else:\n",
    "        feature.append(0.68)\n",
    "        \n",
    "    # acceptance rate of intended major\n",
    "    admissionResMajor = majorAcceptanceRateDict[major]\n",
    "    if len(admissionResMajor) > 10:\n",
    "        feature.append(sum(admissionResMajor)/len(admissionResMajor))\n",
    "    else:\n",
    "        feature.append(0.58)\n",
    "    \n",
    "    # difference between the GPA and the median GPA of the target university\n",
    "    medianGPAUni = 3.6\n",
    "    if len(universityGPADict[uniName]) > 10:\n",
    "        medianGPAUni = np.median(universityGPADict[uniName])\n",
    "    feature.append(float(gpa) - medianGPAUni)\n",
    "    \n",
    "    # difference between the GPA and the median GPA of the intended major\n",
    "    medianGPAMajor = 3.6\n",
    "    if len(majorGPADict[major]) > 10:\n",
    "        medianGPAMajor = np.median(majorGPADict[major])\n",
    "    feature.append(float(gpa) - medianGPAMajor)\n",
    "\n",
    "    # degree type\n",
    "    if degree == 'PhD':\n",
    "        feature += [1,0]\n",
    "    else:\n",
    "        feature += [0,1]\n",
    "    \n",
    "    greVMedian = 80;\n",
    "    if len(majorGREVDict[major]) > 10:\n",
    "        greVMedian = np.median(majorGREVDict[major])\n",
    "        \n",
    "    greQMedian = 77;\n",
    "    if len(majorGREQDict[major]) > 10:\n",
    "        greQMedian = np.median(majorGREQDict[major])\n",
    "    \n",
    "    # GRE percentile\n",
    "    if isNewGRE == 'True':\n",
    "            feature.append(newGREPercentileDict[float(greV)][0] - greVMedian)\n",
    "            feature.append(newGREPercentileDict[float(greQ)][1] - greQMedian)\n",
    "    else:\n",
    "            feature.append(oldGREPercentileDict[float(greV)][0] - greVMedian)\n",
    "            feature.append(oldGREPercentileDict[float(greQ)][1] - greQMedian)\n",
    "    \n",
    "    # difference between GRE writing score and the GRE writing score of target university\n",
    "    greWMedianUni = 4\n",
    "    if len(universityGREWDict[uniName]) > 10:\n",
    "        greWMedianUni = np.median(universityGREWDict[uniName])\n",
    "        \n",
    "    if greW != '':\n",
    "        feature.append(float(greW) - greWMedianUni)\n",
    "    else:\n",
    "        feature.append(0)\n",
    "    \n",
    "#     difference between GRE writing score and the GRE writing score of intended major\n",
    "    greWMedianMajor = 4\n",
    "    if len(majorGREWDict[major]) > 10:\n",
    "        greWMedianMajor = np.median(majorGREWDict[major])\n",
    "        \n",
    "    if greW != '':\n",
    "        feature.append(float(greW) - greWMedianMajor)\n",
    "    else:\n",
    "        feature.append(0)\n",
    "    \n",
    "    # residency status\n",
    "    if status == 'American':\n",
    "        feature += [1,0,0,0]\n",
    "    elif status == 'International with US Degree':\n",
    "        feature += [0,1,0,0]\n",
    "    elif status == 'International':\n",
    "        feature += [0,0,1,0]\n",
    "    else:\n",
    "        feature += [0,0,0,1]\n",
    "    \n",
    "    comment = comment.lower()\n",
    "    comment = ''.join([c for c in comment if c not in string.punctuation]).split()\n",
    "    wordSet = set()\n",
    "    \n",
    "    # comment analysis (unigram)\n",
    "    for word in comment:\n",
    "        word = stemmer.stem(word)\n",
    "        wordSet.add(word)\n",
    "       \n",
    "    feature += [w in wordSet for w in tops]\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 rowid \tINTEGER PRIMARY KEY \tA unique integer ID identifying the row. There are 271,807 rows.\n",
    "# 1 uni_name \tTEXT \tThe name of the university. The uncleaned field is user-supplied, and very noisy, containing 10,297 distinct strings. The cleaned version reduces this number to 2708. 98.5% of university names are clean.\n",
    "# 2 major \tTEXT \tThe intended major. This field isn't cleaned and is user-supplied and also noisy. It contains 18,957 distinct strings, the most common of which are \"Computer Science\", \"Economics\" and \"English\".\n",
    "# 3 degree \tTEXT(5) \tThe degree to be earned. This field is cleaned and takes the following values: \"PhD\", \"MS\", \"MEng\", \"MBA\", \"MFA\", \"MA\", and \"Other\". The top 3 are \"PhD\", \"MS\" and \"Other\".\n",
    "# 4 season \tTEXT(3) \tThe season is a three letter string of the form [SF][0-9]{2}. \"S\" is for admission into the Spring semester and \"F\" represents Fall. The two numbers represent the year for which admission is being sought.\n",
    "# 5 decision \tTEXT(15) \tThe decision being reported. This field takes the following values: \"Accepted\", \"Rejected\", \"Wait listed\", \"Interview\" and \"Other\".\n",
    "# 6 decision_method \tTEXT(15) \tThe method in which the decision was reported. The field takes the following values: \"E-mail\", \"Website\", \"Phone\", \"Postal Service\" and \"Other\".\n",
    "# 7 decision_date \tTEXT(10) \tThe date the decision was made in the form \"dd-mm-yyyy\".\n",
    "# 8 decision_timestamp \tINTEGER \tThe timestamp since epoch that the decision was made.\n",
    "# 9 ugrad_gpa \tFLOAT \tThe candidate's self-reported undergraduate GPA. Typically on a 4.0 scale, but often scores on 10.0 scales are reported with no clear disambiguation.\n",
    "# 10 gre_verbal \tINTEGER \tThe candidate's self-reported GRE Verbal score. If is_new_gre is 1, this field should be between 130 and 170 inclusive. If 0, then it should be between 200 and 800 exclusive.\n",
    "# 11 gre_quant \tINTEGER \tThe candidate's self-reported GRE Quantitative score. If is_new_gre is 1, this field should be between 130 and 170 inclusive. If 0, then it should be between 200 and 800 exclusive.\n",
    "# 12 gre_writing \tFLOAT \tThe candidate's self-reported GRE Writing score. It is on a scale of 0.0 to 6.0.\n",
    "# 13 is_new_gre \tINTEGER \tWhether or not the candidate took the new GRE examination (where scores range from 130 to 170) or not.\n",
    "# 14 gre_subject \tINTEGER \tThe candidate's self-reported GRE Subject Test score. It can range in the 900s. Presumably, given that this is a CS dataset, I'd assume the subject in question is Computer Science.\n",
    "# 15 status \tTEXT(28) \tThe status of the candidate. Can take on 4 different values - \"American\", \"International\", \"International with US degree\" and \"Other\".\n",
    "# 16 post_data \tTEXT(10) \tThe date on which this report was posted by the candidate in the form \"dd-mm-yyyy\".\n",
    "# 17 post_timestamp \tINTEGER \tThe timestamp since epoch that the post was made.\n",
    "# 18 comments \tBLOB \tAll user added comments to the post he submitted\n",
    "\n",
    "\n",
    "\n",
    "# To play around with the predictor\n",
    "# fill up the parameter array according to the above schema\n",
    "#['', 'School name', 'Major name', 'Degree type', '','','','','','GPA','GRE Verbal','GRE Quant', 'GRE Writing', \n",
    "#'is New GRE or not', '', 'Residency status', '','','Comments(reserach/reward/interns)']\n",
    "#\n",
    "# Example:\n",
    "# feature = feat(['','Columbia University','Math','MS','','','','','','3.3','160','165','3','True','','International','','',\"\"])\n",
    "# rdf.predict_proba([feature])[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
